{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "comparative-psychiatry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/satouwataru/Desktop/DiveIntoCode/git/diveintocode-ml/GraduationWork/v4/codes/model\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "secondary-negotiation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/satouwataru/Desktop/DiveIntoCode/git/diveintocode-ml/GraduationWork/v4/codes\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "former-world",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/satouwataru/Desktop/DiveIntoCode/git/diveintocode-ml/GraduationWork/v4\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cross-karen",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "sustained-baking",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import codes.common as c\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pickle\n",
    "import optuna\n",
    "\n",
    "'''\n",
    "model : XGboost\n",
    "description:試合結果の2値分類（分,その他）\n",
    "''' \n",
    "class model():\n",
    "    def __init__(self):\n",
    "        self.common = c.common()\n",
    "        self.common.PY_NAME = 'model_8'\n",
    "        self.y_col = 'y_even_flg'\n",
    "        \n",
    "        self.x_train, self.x_val, self.x_test = None, None, None\n",
    "        self.y_train, self.y_val = None, None\n",
    "        self.model = None\n",
    "        self.f_model_name = None\n",
    "        \n",
    "    def get_y_pred(self):\n",
    "        \n",
    "        self.preprocessing()\n",
    "        \n",
    "        self.set_model()\n",
    "        \n",
    "        y_pred = self.predict()\n",
    "        \n",
    "        df_y = pd.DataFrame(y_pred, columns = ['pred_m8'])\n",
    "        \n",
    "        return df_y\n",
    "        \n",
    "    def predict(self):\n",
    "        dtest = xgb.DMatrix(self.x_test)\n",
    "        \n",
    "        y_pred = self.model.predict(dtest)\n",
    "        return y_pred\n",
    "    \n",
    "    def set_model(self):\n",
    "        year = str(self.x_test[:1]['年月日'].values[0])[:4]\n",
    "        self.f_model_name = 'data/model/base_models/model_8/model_for_' + year +'.sav'\n",
    "        try:\n",
    "            self.model = pickle.load(open(self.f_model_name, 'rb'))\n",
    "        except:\n",
    "            self.fit()\n",
    "            \n",
    "    def fit(self):\n",
    "        self.dtrain = xgb.DMatrix(self.x_train, label=self.y_train)\n",
    "        dval = xgb.DMatrix(self.x_val, label=self.y_val)\n",
    "        study = optuna.create_study()\n",
    "        study.optimize(self.objective, n_trials=2)#50)\n",
    "        \n",
    "        trial = study.best_trial\n",
    "        \n",
    "        self.params[\"max_depth\"] = trial.params[\"max_depth\"]\n",
    "        self.params[\"eta\"] = trial.params[\"eta\"]\n",
    "\n",
    "        model = xgb.train(params=self.params,\n",
    "                  dtrain=self.dtrain,\n",
    "                  num_boost_round=1000,\n",
    "                  early_stopping_rounds=50,\n",
    "                  evals=[(dval, \"test\")])\n",
    "\n",
    "        self.model = model\n",
    "        # 保存\n",
    "        pickle.dump(self.model, open(self.f_model_name, 'wb'))\n",
    "        # Accuracy の計算\n",
    "        y_pred = self.model.predict(dval)\n",
    "        \n",
    "        accuracy = sum(self.y_val == y_pred) / len(self.y_val)\n",
    "        print('accuracy:', accuracy)\n",
    "        \n",
    "    def objective(self, trial):\n",
    "        self.params = {\n",
    "            \"silent\": 1,\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 1, 9),\n",
    "            \"min_child_weight\": 1,\n",
    "            \"eta\": trial.suggest_loguniform(\"eta\", 0.01, 1.0),\n",
    "            \"tree_method\": \"exact\",\n",
    "            \"objective\": \"multi:softmax\",\n",
    "            \"num_class\": 2,\n",
    "            \"predictor\": \"cpu_predictor\"  \n",
    "        }\n",
    "        cv_results = xgb.cv(\n",
    "            self.params,\n",
    "            self.dtrain,\n",
    "            num_boost_round=1000,\n",
    "            seed=0,\n",
    "            nfold=5, # CVの分割数\n",
    "#             metrics={\"rmse\"},\n",
    "            early_stopping_rounds=200\n",
    "        )\n",
    "        return cv_results[\"test-merror-mean\"].min()\n",
    "\n",
    "    def preprocessing(self):\n",
    "        # 読み込み\n",
    "        df = pd.read_csv(\"data/model/base_models/preprocessing/preprocessed_1.csv\", index_col=0)\n",
    "        # 引き分けとその他のデータ数を揃える\n",
    "        train = df[df['train_test']=='train'].drop(columns = ['train_test'])\n",
    "        train = train[train['y_goal_deff'] < 2].sort_values('年月日', ascending=False)\n",
    "        train_0 = train[train['y_H_result'] == 0]\n",
    "        train_1 = train[train['y_H_result'] == 1]\n",
    "        train_2 = train[train['y_H_result'] == 2]\n",
    "        n_row_0 = train_0.shape[0]\n",
    "        n_row_1 = train_1.shape[0]\n",
    "        n_row_2 = train_2.shape[0]\n",
    "        n_row = min(min(n_row_1,n_row_2)*2, n_row_0)\n",
    "        train = pd.concat([train_0.iloc[:n_row], train_1.iloc[:n_row//2], train_2.iloc[:n_row//2]])\n",
    "        # 不要な列を削除\n",
    "        train = self.common.drop_y_col(train, self.y_col)\n",
    "        # train, val, testに分割\n",
    "        x_train = train.drop(columns = self.y_col)\n",
    "        y_train = train[self.y_col]\n",
    "        self.x_train, self.x_val, self.y_train, self.y_val = train_test_split(x_train, y_train, stratify = y_train)\n",
    "        \n",
    "        test = df[df['train_test']=='test'].drop(columns = ['train_test'])\n",
    "        test = self.common.drop_y_col(test, self.y_col)\n",
    "        self.x_test = test.drop(columns = self.y_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "electoral-dodge",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 02:24:47,805]\u001b[0m A new study created in memory with name: no-name-1cc5f854-ab51-4d1e-af06-c0ba966de1e9\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:24:47] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1593723618214/work/src/learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:24:47] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1593723618214/work/src/learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:24:47] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1593723618214/work/src/learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:24:47] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1593723618214/work/src/learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:24:47] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1593723618214/work/src/learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 02:24:49,147]\u001b[0m Trial 0 finished with value: 0.2584274 and parameters: {'max_depth': 2, 'eta': 0.14478718213548927}. Best is trial 0 with value: 0.2584274.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:24:49] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1593723618214/work/src/learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttest-merror:0.26173\n",
      "Will train until test-merror hasn't improved in 5 rounds.\n",
      "[1]\ttest-merror:0.26444\n",
      "[2]\ttest-merror:0.26444\n",
      "[3]\ttest-merror:0.26444\n",
      "[4]\ttest-merror:0.26444\n",
      "[5]\ttest-merror:0.26444\n",
      "Stopping. Best iteration:\n",
      "[0]\ttest-merror:0.26173\n",
      "\n",
      "accuracy: 0.7355595667870036\n"
     ]
    }
   ],
   "source": [
    "m = model()\n",
    "df = m.get_y_pred()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "responsible-davis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_m8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pred_m8\n",
       "0      0.0\n",
       "1      0.0\n",
       "2      0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlike-cursor",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
