{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "addressed-sharing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/satouwataru/Desktop/DiveIntoCode/git/diveintocode-ml/GraduationWork/v1/codes\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "promising-drunk",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/satouwataru/Desktop/DiveIntoCode/git/diveintocode-ml/GraduationWork/v1\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "interested-position",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import optuna.integration.lightgbm as lgb_o\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "temporal-knock",
   "metadata": {},
   "outputs": [],
   "source": [
    "class model():\n",
    "\n",
    "    def __init__(self, train_columns):\n",
    "        self.model = None\n",
    "        self.train_columns = train_columns\n",
    "        \n",
    "    def fit(self, yyyyMMdd):\n",
    "\n",
    "        y_col = 'goal_difference'\n",
    "        data = pd.read_csv(\"data/model/preprocessing.csv\", index_col=0).reset_index(drop = True)\n",
    "        \n",
    "        data = data[self.train_columns + [y_col]]\n",
    "        df = data[data['年月日'] < yyyyMMdd]\n",
    "\n",
    "        train, val = train_test_split(df, train_size=0.80)\n",
    "        test = data[data['年月日'] >= yyyyMMdd]\n",
    "\n",
    "        x_train = train.drop(columns = y_col)\n",
    "        x_val = val.drop(columns = y_col)\n",
    "        x_test = test.drop(columns = y_col)\n",
    "\n",
    "        y_train = train[y_col]\n",
    "        y_val = val[y_col]\n",
    "        y_test = test[y_col]\n",
    "\n",
    "        lgb_train = lgb_o.Dataset(x_train, y_train)\n",
    "        lgb_eval = lgb_o.Dataset(x_val, y_val) \n",
    "        # LightGBM parameters\n",
    "        params = {\n",
    "            'objective': 'regression', # 回帰  \n",
    "            'metric': 'rmse', # rsme(平均二乗誤差の平方根) \n",
    "        }\n",
    "        # モデルの学習\n",
    "        model = lgb_o.train(params,\n",
    "                          train_set=lgb_train,\n",
    "                          valid_sets=lgb_eval,\n",
    "                          early_stopping_rounds=100,\n",
    "                          verbose_eval=200,\n",
    "                          )\n",
    "        \n",
    "        self.model = model\n",
    "        \n",
    "        # テストデータの予測\n",
    "        y_pred = model.predict(x_test, num_iteration=model.best_iteration)\n",
    "        # rmse : 平均二乗誤差の平方根\n",
    "        mse = mean_squared_error(y_test, y_pred) # MSE(平均二乗誤差)の算出\n",
    "        rmse = np.sqrt(mse) # RSME = √MSEの算出\n",
    "        print(y_col,' rmse : ', rmse)\n",
    "        \n",
    "    def predict(self, x_test):\n",
    "\n",
    "        y_pred = self.model.predict(x_test, num_iteration=self.model.best_iteration)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "latest-antibody",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "interracial-awareness",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-07 17:36:12,282]\u001b[0m A new study created in memory with name: no-name-a3ba678d-4acc-418e-aa80-bca0c7a84b19\u001b[0m\n",
      "feature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001519 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7664\n",
      "[LightGBM] [Info] Number of data points in the train set: 6992, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.170624\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 1.196729:  14%|#4        | 1/7 [00:00<00:02,  2.27it/s]\u001b[32m[I 2021-05-07 17:36:12,739]\u001b[0m Trial 0 finished with value: 1.19672928936106 and parameters: {'feature_fraction': 0.4}. Best is trial 0 with value: 1.19672928936106.\u001b[0m\n",
      "feature_fraction, val_score: 1.196729:  14%|#4        | 1/7 [00:00<00:02,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[77]\tvalid_0's rmse: 1.19673\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003431 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7664\n",
      "[LightGBM] [Info] Number of data points in the train set: 6992, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.170624\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 1.196729:  29%|##8       | 2/7 [00:00<00:02,  2.00it/s]\u001b[32m[I 2021-05-07 17:36:13,280]\u001b[0m Trial 1 finished with value: 1.199500523891598 and parameters: {'feature_fraction': 0.5}. Best is trial 0 with value: 1.19672928936106.\u001b[0m\n",
      "feature_fraction, val_score: 1.196729:  29%|##8       | 2/7 [00:00<00:02,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalid_0's rmse: 1.20418\n",
      "Early stopping, best iteration is:\n",
      "[157]\tvalid_0's rmse: 1.1995\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003220 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7664\n",
      "[LightGBM] [Info] Number of data points in the train set: 6992, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.170624\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 1.193583:  43%|####2     | 3/7 [00:01<00:02,  1.96it/s]\u001b[32m[I 2021-05-07 17:36:13,803]\u001b[0m Trial 2 finished with value: 1.193582676180351 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 2 with value: 1.193582676180351.\u001b[0m\n",
      "feature_fraction, val_score: 1.193583:  43%|####2     | 3/7 [00:01<00:02,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalid_0's rmse: 1.19556\n",
      "Early stopping, best iteration is:\n",
      "[151]\tvalid_0's rmse: 1.19358\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003528 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7664\n",
      "[LightGBM] [Info] Number of data points in the train set: 6992, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.170624\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 1.193583:  57%|#####7    | 4/7 [00:01<00:01,  2.19it/s]\u001b[32m[I 2021-05-07 17:36:14,176]\u001b[0m Trial 3 finished with value: 1.1968549959656318 and parameters: {'feature_fraction': 0.8}. Best is trial 2 with value: 1.193582676180351.\u001b[0m\n",
      "feature_fraction, val_score: 1.193583:  57%|#####7    | 4/7 [00:01<00:01,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[97]\tvalid_0's rmse: 1.19685\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002301 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7664\n",
      "[LightGBM] [Info] Number of data points in the train set: 6992, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.170624\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 1.193583:  71%|#######1  | 5/7 [00:02<00:00,  2.53it/s]\u001b[32m[I 2021-05-07 17:36:14,462]\u001b[0m Trial 4 finished with value: 1.1967760159355796 and parameters: {'feature_fraction': 0.6}. Best is trial 2 with value: 1.193582676180351.\u001b[0m\n",
      "feature_fraction, val_score: 1.193583:  71%|#######1  | 5/7 [00:02<00:00,  2.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[62]\tvalid_0's rmse: 1.19678\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003093 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7664\n",
      "[LightGBM] [Info] Number of data points in the train set: 6992, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.170624\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 1.193583:  86%|########5 | 6/7 [00:02<00:00,  2.67it/s]\u001b[32m[I 2021-05-07 17:36:14,798]\u001b[0m Trial 5 finished with value: 1.1955125379735907 and parameters: {'feature_fraction': 0.7}. Best is trial 2 with value: 1.193582676180351.\u001b[0m\n",
      "feature_fraction, val_score: 1.193583:  86%|########5 | 6/7 [00:02<00:00,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[76]\tvalid_0's rmse: 1.19551\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002603 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7664\n",
      "[LightGBM] [Info] Number of data points in the train set: 6992, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.170624\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 1.193583: 100%|##########| 7/7 [00:02<00:00,  2.63it/s]\u001b[32m[I 2021-05-07 17:36:15,190]\u001b[0m Trial 6 finished with value: 1.194199820496716 and parameters: {'feature_fraction': 1.0}. Best is trial 2 with value: 1.193582676180351.\u001b[0m\n",
      "feature_fraction, val_score: 1.193583: 100%|##########| 7/7 [00:02<00:00,  2.42it/s]\n",
      "num_leaves, val_score: 1.193583:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[57]\tvalid_0's rmse: 1.1942\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003211 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7664\n",
      "[LightGBM] [Info] Number of data points in the train set: 6992, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.170624\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 1.193583:   5%|5         | 1/20 [00:01<00:24,  1.28s/it]\u001b[32m[I 2021-05-07 17:36:16,477]\u001b[0m Trial 7 finished with value: 1.2220121789975935 and parameters: {'num_leaves': 207}. Best is trial 7 with value: 1.2220121789975935.\u001b[0m\n",
      "num_leaves, val_score: 1.193583:   5%|5         | 1/20 [00:01<00:24,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[59]\tvalid_0's rmse: 1.22201\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002947 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7664\n",
      "[LightGBM] [Info] Number of data points in the train set: 6992, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.170624\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 1.193583:  10%|#         | 2/20 [00:02<00:21,  1.19s/it]\u001b[32m[I 2021-05-07 17:36:17,603]\u001b[0m Trial 8 finished with value: 1.2173406497649664 and parameters: {'num_leaves': 143}. Best is trial 8 with value: 1.2173406497649664.\u001b[0m\n",
      "num_leaves, val_score: 1.193583:  10%|#         | 2/20 [00:02<00:21,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[50]\tvalid_0's rmse: 1.21734\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002686 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7664\n",
      "[LightGBM] [Info] Number of data points in the train set: 6992, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.170624\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 1.193583:  15%|#5        | 3/20 [00:03<00:22,  1.30s/it]\u001b[32m[I 2021-05-07 17:36:19,025]\u001b[0m Trial 9 finished with value: 1.21710699669532 and parameters: {'num_leaves': 221}. Best is trial 9 with value: 1.21710699669532.\u001b[0m\n",
      "num_leaves, val_score: 1.193583:  15%|#5        | 3/20 [00:03<00:22,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[64]\tvalid_0's rmse: 1.21711\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003103 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7664\n",
      "[LightGBM] [Info] Number of data points in the train set: 6992, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.170624\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 1.193583:  20%|##        | 4/20 [00:05<00:20,  1.28s/it]\u001b[32m[I 2021-05-07 17:36:20,277]\u001b[0m Trial 10 finished with value: 1.224402045953413 and parameters: {'num_leaves': 202}. Best is trial 9 with value: 1.21710699669532.\u001b[0m\n",
      "num_leaves, val_score: 1.193583:  20%|##        | 4/20 [00:05<00:20,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[60]\tvalid_0's rmse: 1.2244\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002193 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7664\n",
      "[LightGBM] [Info] Number of data points in the train set: 6992, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.170624\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 1.193583:  25%|##5       | 5/20 [00:06<00:19,  1.28s/it]\u001b[32m[I 2021-05-07 17:36:21,560]\u001b[0m Trial 11 finished with value: 1.2106553754231295 and parameters: {'num_leaves': 185}. Best is trial 11 with value: 1.2106553754231295.\u001b[0m\n",
      "num_leaves, val_score: 1.193583:  25%|##5       | 5/20 [00:06<00:19,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[75]\tvalid_0's rmse: 1.21066\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002891 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7664\n",
      "[LightGBM] [Info] Number of data points in the train set: 6992, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.170624\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 1.193583:  30%|###       | 6/20 [00:07<00:17,  1.28s/it]\u001b[32m[I 2021-05-07 17:36:22,825]\u001b[0m Trial 12 finished with value: 1.2261173806729968 and parameters: {'num_leaves': 256}. Best is trial 11 with value: 1.2106553754231295.\u001b[0m\n",
      "num_leaves, val_score: 1.193583:  30%|###       | 6/20 [00:07<00:17,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[41]\tvalid_0's rmse: 1.22612\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003443 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7664\n",
      "[LightGBM] [Info] Number of data points in the train set: 6992, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.170624\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 1.193583:  35%|###5      | 7/20 [00:08<00:14,  1.10s/it]\u001b[32m[I 2021-05-07 17:36:23,572]\u001b[0m Trial 13 finished with value: 1.2186731892408562 and parameters: {'num_leaves': 83}. Best is trial 11 with value: 1.2106553754231295.\u001b[0m\n",
      "num_leaves, val_score: 1.193583:  35%|###5      | 7/20 [00:08<00:14,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[57]\tvalid_0's rmse: 1.21867\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002334 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7664\n",
      "[LightGBM] [Info] Number of data points in the train set: 6992, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.170624\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 1.193583:  40%|####      | 8/20 [00:08<00:09,  1.21it/s]\u001b[32m[I 2021-05-07 17:36:23,809]\u001b[0m Trial 14 finished with value: 1.1939579303440602 and parameters: {'num_leaves': 9}. Best is trial 14 with value: 1.1939579303440602.\u001b[0m\n",
      "num_leaves, val_score: 1.193583:  40%|####      | 8/20 [00:08<00:09,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalid_0's rmse: 1.19591\n",
      "Early stopping, best iteration is:\n",
      "[113]\tvalid_0's rmse: 1.19396\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002219 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7664\n",
      "[LightGBM] [Info] Number of data points in the train set: 6992, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.170624\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 1.193583:  45%|####5     | 9/20 [00:10<00:12,  1.12s/it]\u001b[32m[I 2021-05-07 17:36:25,582]\u001b[0m Trial 15 finished with value: 1.2226006377727634 and parameters: {'num_leaves': 220}. Best is trial 14 with value: 1.1939579303440602.\u001b[0m\n",
      "num_leaves, val_score: 1.193583:  45%|####5     | 9/20 [00:10<00:12,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[56]\tvalid_0's rmse: 1.2226\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003238 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7664\n",
      "[LightGBM] [Info] Number of data points in the train set: 6992, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.170624\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 1.185873:  50%|#####     | 10/20 [00:10<00:08,  1.16it/s]\u001b[32m[I 2021-05-07 17:36:25,856]\u001b[0m Trial 16 finished with value: 1.1858732654624928 and parameters: {'num_leaves': 16}. Best is trial 16 with value: 1.1858732654624928.\u001b[0m\n",
      "num_leaves, val_score: 1.185873:  50%|#####     | 10/20 [00:10<00:08,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[78]\tvalid_0's rmse: 1.18587\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002390 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7664\n",
      "[LightGBM] [Info] Number of data points in the train set: 6992, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.170624\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 1.185873:  55%|#####5    | 11/20 [00:10<00:06,  1.43it/s]\u001b[32m[I 2021-05-07 17:36:26,184]\u001b[0m Trial 17 finished with value: 1.1858732654624928 and parameters: {'num_leaves': 16}. Best is trial 16 with value: 1.1858732654624928.\u001b[0m\n",
      "num_leaves, val_score: 1.185873:  55%|#####5    | 11/20 [00:10<00:06,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[78]\tvalid_0's rmse: 1.18587\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002280 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7664\n",
      "[LightGBM] [Info] Number of data points in the train set: 6992, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.170624\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 1.185873:  60%|######    | 12/20 [00:11<00:04,  1.78it/s]\u001b[32m[I 2021-05-07 17:36:26,439]\u001b[0m Trial 18 finished with value: 1.191784611132684 and parameters: {'num_leaves': 10}. Best is trial 16 with value: 1.1858732654624928.\u001b[0m\n",
      "num_leaves, val_score: 1.185873:  60%|######    | 12/20 [00:11<00:04,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[98]\tvalid_0's rmse: 1.19178\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003373 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7664\n",
      "[LightGBM] [Info] Number of data points in the train set: 6992, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.170624\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 1.185873:  65%|######5   | 13/20 [00:11<00:04,  1.63it/s]\u001b[32m[I 2021-05-07 17:36:27,173]\u001b[0m Trial 19 finished with value: 1.205234771019803 and parameters: {'num_leaves': 59}. Best is trial 16 with value: 1.1858732654624928.\u001b[0m\n",
      "num_leaves, val_score: 1.185873:  65%|######5   | 13/20 [00:11<00:04,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[61]\tvalid_0's rmse: 1.20523\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7664\n",
      "[LightGBM] [Info] Number of data points in the train set: 6992, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.170624\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 1.185873:  70%|#######   | 14/20 [00:12<00:03,  1.64it/s]\u001b[32m[I 2021-05-07 17:36:27,766]\u001b[0m Trial 20 finished with value: 1.2085354150306402 and parameters: {'num_leaves': 54}. Best is trial 16 with value: 1.1858732654624928.\u001b[0m\n",
      "num_leaves, val_score: 1.185873:  70%|#######   | 14/20 [00:12<00:03,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[90]\tvalid_0's rmse: 1.20854\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002866 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7664\n",
      "[LightGBM] [Info] Number of data points in the train set: 6992, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.170624\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 1.185873:  75%|#######5  | 15/20 [00:12<00:02,  1.82it/s]\u001b[32m[I 2021-05-07 17:36:28,182]\u001b[0m Trial 21 finished with value: 1.1956214518721593 and parameters: {'num_leaves': 36}. Best is trial 16 with value: 1.1858732654624928.\u001b[0m\n",
      "num_leaves, val_score: 1.185873:  75%|#######5  | 15/20 [00:12<00:02,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[67]\tvalid_0's rmse: 1.19562\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003613 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7664\n",
      "[LightGBM] [Info] Number of data points in the train set: 6992, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.170624\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 1.185873:  80%|########  | 16/20 [00:13<00:02,  1.62it/s]\u001b[32m[I 2021-05-07 17:36:28,955]\u001b[0m Trial 22 finished with value: 1.2162774439727149 and parameters: {'num_leaves': 121}. Best is trial 16 with value: 1.1858732654624928.\u001b[0m\n",
      "num_leaves, val_score: 1.185873:  80%|########  | 16/20 [00:13<00:02,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[40]\tvalid_0's rmse: 1.21628\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002309 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7664\n",
      "[LightGBM] [Info] Number of data points in the train set: 6992, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.170624\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 1.185873:  85%|########5 | 17/20 [00:14<00:01,  1.56it/s]\u001b[32m[I 2021-05-07 17:36:29,644]\u001b[0m Trial 23 finished with value: 1.2083842555888273 and parameters: {'num_leaves': 98}. Best is trial 16 with value: 1.1858732654624928.\u001b[0m\n",
      "num_leaves, val_score: 1.185873:  85%|########5 | 17/20 [00:14<00:01,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[39]\tvalid_0's rmse: 1.20838\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002942 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7664\n",
      "[LightGBM] [Info] Number of data points in the train set: 6992, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.170624\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 1.18681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 1.184582:  90%|######### | 18/20 [00:14<00:01,  1.91it/s]\u001b[32m[I 2021-05-07 17:36:29,901]\u001b[0m Trial 24 finished with value: 1.1845819789883931 and parameters: {'num_leaves': 5}. Best is trial 24 with value: 1.1845819789883931.\u001b[0m\n",
      "num_leaves, val_score: 1.184582:  90%|######### | 18/20 [00:14<00:01,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[255]\tvalid_0's rmse: 1.18458\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002880 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7664\n",
      "[LightGBM] [Info] Number of data points in the train set: 6992, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.170624\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 1.184582:  95%|#########5| 19/20 [00:15<00:00,  1.93it/s]\u001b[32m[I 2021-05-07 17:36:30,405]\u001b[0m Trial 25 finished with value: 1.193582676180351 and parameters: {'num_leaves': 31}. Best is trial 24 with value: 1.1845819789883931.\u001b[0m\n",
      "num_leaves, val_score: 1.184582:  95%|#########5| 19/20 [00:15<00:00,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalid_0's rmse: 1.19556\n",
      "Early stopping, best iteration is:\n",
      "[151]\tvalid_0's rmse: 1.19358\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003074 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7664\n",
      "[LightGBM] [Info] Number of data points in the train set: 6992, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.170624\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 1.184582: 100%|##########| 20/20 [00:15<00:00,  1.70it/s]\u001b[32m[I 2021-05-07 17:36:31,153]\u001b[0m Trial 26 finished with value: 1.1982626202451425 and parameters: {'num_leaves': 76}. Best is trial 24 with value: 1.1845819789883931.\u001b[0m\n",
      "num_leaves, val_score: 1.184582: 100%|##########| 20/20 [00:15<00:00,  1.25it/s]\n",
      "bagging, val_score: 1.184582:  10%|#         | 1/10 [00:00<00:01,  5.85it/s]\u001b[32m[I 2021-05-07 17:36:31,330]\u001b[0m Trial 27 finished with value: 1.1983106980975178 and parameters: {'bagging_fraction': 0.4958611332500722, 'bagging_freq': 2}. Best is trial 27 with value: 1.1983106980975178.\u001b[0m\n",
      "bagging, val_score: 1.184582:  10%|#         | 1/10 [00:00<00:01,  5.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[88]\tvalid_0's rmse: 1.19826\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003726 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7664\n",
      "[LightGBM] [Info] Number of data points in the train set: 6992, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.170624\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 1.19966\n",
      "Early stopping, best iteration is:\n",
      "[105]\tvalid_0's rmse: 1.19831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 1.184582:  20%|##        | 2/10 [00:00<00:01,  5.33it/s]\u001b[32m[I 2021-05-07 17:36:31,529]\u001b[0m Trial 28 finished with value: 1.1917955181505344 and parameters: {'bagging_fraction': 0.73800460637546, 'bagging_freq': 3}. Best is trial 28 with value: 1.1917955181505344.\u001b[0m\n",
      "bagging, val_score: 1.184582:  20%|##        | 2/10 [00:00<00:01,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002836 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7664\n",
      "[LightGBM] [Info] Number of data points in the train set: 6992, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.170624\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 1.19648\n",
      "Early stopping, best iteration is:\n",
      "[141]\tvalid_0's rmse: 1.1918\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002620 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7664\n",
      "[LightGBM] [Info] Number of data points in the train set: 6992, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.170624\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 1.18914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 1.184582:  30%|###       | 3/10 [00:00<00:01,  4.08it/s]\u001b[32m[I 2021-05-07 17:36:31,842]\u001b[0m Trial 29 finished with value: 1.186398195465075 and parameters: {'bagging_fraction': 0.9145675438895972, 'bagging_freq': 4}. Best is trial 29 with value: 1.186398195465075.\u001b[0m\n",
      "bagging, val_score: 1.184582:  30%|###       | 3/10 [00:00<00:01,  4.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[293]\tvalid_0's rmse: 1.1864\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002105 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7664\n",
      "[LightGBM] [Info] Number of data points in the train set: 6992, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.170624\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 1.18608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 1.184582:  40%|####      | 4/10 [00:00<00:01,  3.95it/s]\u001b[32m[I 2021-05-07 17:36:32,107]\u001b[0m Trial 30 finished with value: 1.1846348649819023 and parameters: {'bagging_fraction': 0.808787711650221, 'bagging_freq': 6}. Best is trial 30 with value: 1.1846348649819023.\u001b[0m\n",
      "bagging, val_score: 1.184582:  40%|####      | 4/10 [00:00<00:01,  3.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[261]\tvalid_0's rmse: 1.18463\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002348 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7664\n",
      "[LightGBM] [Info] Number of data points in the train set: 6992, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.170624\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 1.18703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 1.183716:  50%|#####     | 5/10 [00:01<00:01,  4.21it/s]\u001b[32m[I 2021-05-07 17:36:32,317]\u001b[0m Trial 31 finished with value: 1.1837158574344264 and parameters: {'bagging_fraction': 0.8735273474110961, 'bagging_freq': 7}. Best is trial 31 with value: 1.1837158574344264.\u001b[0m\n",
      "bagging, val_score: 1.183716:  50%|#####     | 5/10 [00:01<00:01,  4.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[216]\tvalid_0's rmse: 1.18372\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002502 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7664\n",
      "[LightGBM] [Info] Number of data points in the train set: 6992, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.170624\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 1.19101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 1.183716:  60%|######    | 6/10 [00:01<00:00,  4.34it/s]\u001b[32m[I 2021-05-07 17:36:32,535]\u001b[0m Trial 32 finished with value: 1.188543494750288 and parameters: {'bagging_fraction': 0.8730608094027859, 'bagging_freq': 1}. Best is trial 31 with value: 1.1837158574344264.\u001b[0m\n",
      "bagging, val_score: 1.183716:  60%|######    | 6/10 [00:01<00:00,  4.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[174]\tvalid_0's rmse: 1.18854\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003867 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7664\n",
      "[LightGBM] [Info] Number of data points in the train set: 6992, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.170624\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 1.19217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 1.183716:  70%|#######   | 7/10 [00:01<00:00,  4.06it/s]\u001b[32m[I 2021-05-07 17:36:32,814]\u001b[0m Trial 33 finished with value: 1.1900797781130905 and parameters: {'bagging_fraction': 0.44108163453325705, 'bagging_freq': 1}. Best is trial 31 with value: 1.1837158574344264.\u001b[0m\n",
      "bagging, val_score: 1.183716:  80%|########  | 8/10 [00:01<00:00,  4.58it/s]\u001b[32m[I 2021-05-07 17:36:32,971]\u001b[0m Trial 34 finished with value: 1.1920980448704448 and parameters: {'bagging_fraction': 0.4207991467582623, 'bagging_freq': 6}. Best is trial 31 with value: 1.1837158574344264.\u001b[0m\n",
      "bagging, val_score: 1.183716:  80%|########  | 8/10 [00:01<00:00,  4.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[261]\tvalid_0's rmse: 1.19008\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003273 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7664\n",
      "[LightGBM] [Info] Number of data points in the train set: 6992, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.170624\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 1.19355\n",
      "Early stopping, best iteration is:\n",
      "[114]\tvalid_0's rmse: 1.1921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 1.183716:  90%|######### | 9/10 [00:01<00:00,  4.81it/s]\u001b[32m[I 2021-05-07 17:36:33,157]\u001b[0m Trial 35 finished with value: 1.1891265087417453 and parameters: {'bagging_fraction': 0.517914482490211, 'bagging_freq': 4}. Best is trial 31 with value: 1.1837158574344264.\u001b[0m\n",
      "bagging, val_score: 1.183716:  90%|######### | 9/10 [00:02<00:00,  4.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002642 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7664\n",
      "[LightGBM] [Info] Number of data points in the train set: 6992, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.170624\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 1.19112\n",
      "Early stopping, best iteration is:\n",
      "[124]\tvalid_0's rmse: 1.18913\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002227 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7664\n",
      "[LightGBM] [Info] Number of data points in the train set: 6992, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.170624\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 1.183716: 100%|##########| 10/10 [00:02<00:00,  4.98it/s]\u001b[32m[I 2021-05-07 17:36:33,342]\u001b[0m Trial 36 finished with value: 1.1960554968412633 and parameters: {'bagging_fraction': 0.5229722861245014, 'bagging_freq': 3}. Best is trial 31 with value: 1.1837158574344264.\u001b[0m\n",
      "bagging, val_score: 1.183716: 100%|##########| 10/10 [00:02<00:00,  4.58it/s]\n",
      "feature_fraction_stage2, val_score: 1.183716:   0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalid_0's rmse: 1.20053\n",
      "Early stopping, best iteration is:\n",
      "[141]\tvalid_0's rmse: 1.19606\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002483 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7664\n",
      "[LightGBM] [Info] Number of data points in the train set: 6992, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.170624\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 1.18592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 1.182349:  17%|#6        | 1/6 [00:00<00:01,  3.60it/s]\u001b[32m[I 2021-05-07 17:36:33,624]\u001b[0m Trial 37 finished with value: 1.1823485872512338 and parameters: {'feature_fraction': 0.82}. Best is trial 37 with value: 1.1823485872512338.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 1.182349:  17%|#6        | 1/6 [00:00<00:01,  3.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[255]\tvalid_0's rmse: 1.18235\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002554 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7664\n",
      "[LightGBM] [Info] Number of data points in the train set: 6992, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.170624\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 1.18957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 1.182349:  33%|###3      | 2/6 [00:00<00:01,  3.78it/s]\u001b[32m[I 2021-05-07 17:36:33,879]\u001b[0m Trial 38 finished with value: 1.1862100748105748 and parameters: {'feature_fraction': 0.852}. Best is trial 37 with value: 1.1823485872512338.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 1.182349:  33%|###3      | 2/6 [00:00<00:01,  3.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[233]\tvalid_0's rmse: 1.18621\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003270 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7664\n",
      "[LightGBM] [Info] Number of data points in the train set: 6992, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.170624\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 1.18852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 1.182349:  50%|#####     | 3/6 [00:00<00:00,  3.54it/s]\u001b[32m[I 2021-05-07 17:36:34,184]\u001b[0m Trial 39 finished with value: 1.1849479573624802 and parameters: {'feature_fraction': 0.8839999999999999}. Best is trial 37 with value: 1.1823485872512338.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 1.182349:  50%|#####     | 3/6 [00:00<00:00,  3.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[265]\tvalid_0's rmse: 1.18495\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002193 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7664\n",
      "[LightGBM] [Info] Number of data points in the train set: 6992, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.170624\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 1.19281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 1.182349:  67%|######6   | 4/6 [00:01<00:00,  3.64it/s]\u001b[32m[I 2021-05-07 17:36:34,446]\u001b[0m Trial 40 finished with value: 1.1887525630440012 and parameters: {'feature_fraction': 0.9799999999999999}. Best is trial 37 with value: 1.1823485872512338.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 1.182349:  67%|######6   | 4/6 [00:01<00:00,  3.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[276]\tvalid_0's rmse: 1.18875\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002553 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7664\n",
      "[LightGBM] [Info] Number of data points in the train set: 6992, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.170624\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 1.1889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 1.182349:  83%|########3 | 5/6 [00:01<00:00,  3.57it/s]\u001b[32m[I 2021-05-07 17:36:34,736]\u001b[0m Trial 41 finished with value: 1.185276620870623 and parameters: {'feature_fraction': 0.948}. Best is trial 37 with value: 1.1823485872512338.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 1.182349:  83%|########3 | 5/6 [00:01<00:00,  3.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[265]\tvalid_0's rmse: 1.18528\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003246 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7664\n",
      "[LightGBM] [Info] Number of data points in the train set: 6992, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.170624\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 1.18835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 1.182349: 100%|##########| 6/6 [00:01<00:00,  3.66it/s]\u001b[32m[I 2021-05-07 17:36:34,996]\u001b[0m Trial 42 finished with value: 1.1857672928662566 and parameters: {'feature_fraction': 0.9159999999999999}. Best is trial 37 with value: 1.1823485872512338.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 1.182349: 100%|##########| 6/6 [00:01<00:00,  3.63it/s]\n",
      "regularization_factors, val_score: 1.182349:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[217]\tvalid_0's rmse: 1.18577\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002956 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7664\n",
      "[LightGBM] [Info] Number of data points in the train set: 6992, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.170624\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 1.1826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 1.179577:   5%|5         | 1/20 [00:00<00:04,  3.83it/s]\u001b[32m[I 2021-05-07 17:36:35,263]\u001b[0m Trial 43 finished with value: 1.1795769222321453 and parameters: {'lambda_l1': 0.0009743297084716502, 'lambda_l2': 6.823380335124969}. Best is trial 43 with value: 1.1795769222321453.\u001b[0m\n",
      "regularization_factors, val_score: 1.179577:   5%|5         | 1/20 [00:00<00:04,  3.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[232]\tvalid_0's rmse: 1.17958\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003034 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7664\n",
      "[LightGBM] [Info] Number of data points in the train set: 6992, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.170624\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 1.179577:  10%|#         | 2/20 [00:00<00:04,  3.71it/s]\u001b[32m[I 2021-05-07 17:36:35,537]\u001b[0m Trial 44 finished with value: 1.1823662396420769 and parameters: {'lambda_l1': 1.4787276225014684e-06, 'lambda_l2': 0.5405236233303649}. Best is trial 43 with value: 1.1795769222321453.\u001b[0m\n",
      "regularization_factors, val_score: 1.179577:  10%|#         | 2/20 [00:00<00:04,  3.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalid_0's rmse: 1.18481\n",
      "Early stopping, best iteration is:\n",
      "[217]\tvalid_0's rmse: 1.18237\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002200 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7664\n",
      "[LightGBM] [Info] Number of data points in the train set: 6992, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.170624\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 1.179577:  15%|#5        | 3/20 [00:00<00:04,  3.66it/s]\u001b[32m[I 2021-05-07 17:36:35,816]\u001b[0m Trial 45 finished with value: 1.1828428861942817 and parameters: {'lambda_l1': 0.1610088318885063, 'lambda_l2': 2.0436913816937577e-06}. Best is trial 43 with value: 1.1795769222321453.\u001b[0m\n",
      "regularization_factors, val_score: 1.179577:  15%|#5        | 3/20 [00:00<00:04,  3.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalid_0's rmse: 1.18577\n",
      "Early stopping, best iteration is:\n",
      "[217]\tvalid_0's rmse: 1.18284\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002300 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7664\n",
      "[LightGBM] [Info] Number of data points in the train set: 6992, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.170624\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 1.179577:  20%|##        | 4/20 [00:01<00:04,  3.65it/s]\u001b[32m[I 2021-05-07 17:36:36,091]\u001b[0m Trial 46 finished with value: 1.1823485799701487 and parameters: {'lambda_l1': 8.75597970320564e-08, 'lambda_l2': 2.621347032780239e-05}. Best is trial 43 with value: 1.1795769222321453.\u001b[0m\n",
      "regularization_factors, val_score: 1.179577:  20%|##        | 4/20 [00:01<00:04,  3.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalid_0's rmse: 1.18592\n",
      "Early stopping, best iteration is:\n",
      "[255]\tvalid_0's rmse: 1.18235\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002894 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7664\n",
      "[LightGBM] [Info] Number of data points in the train set: 6992, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.170624\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 1.179577:  25%|##5       | 5/20 [00:01<00:04,  3.69it/s]\u001b[32m[I 2021-05-07 17:36:36,357]\u001b[0m Trial 47 finished with value: 1.1842106757391448 and parameters: {'lambda_l1': 2.367286003576596e-05, 'lambda_l2': 6.163452220654286}. Best is trial 43 with value: 1.1795769222321453.\u001b[0m\n",
      "regularization_factors, val_score: 1.179577:  25%|##5       | 5/20 [00:01<00:04,  3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalid_0's rmse: 1.18743\n",
      "Early stopping, best iteration is:\n",
      "[222]\tvalid_0's rmse: 1.18421\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002129 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7664\n",
      "[LightGBM] [Info] Number of data points in the train set: 6992, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.170624\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 1.179577:  30%|###       | 6/20 [00:01<00:03,  3.58it/s]\u001b[32m[I 2021-05-07 17:36:36,653]\u001b[0m Trial 48 finished with value: 1.1829333761619911 and parameters: {'lambda_l1': 0.0001096442716175772, 'lambda_l2': 1.5779193435764665}. Best is trial 43 with value: 1.1795769222321453.\u001b[0m\n",
      "regularization_factors, val_score: 1.179577:  30%|###       | 6/20 [00:01<00:03,  3.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalid_0's rmse: 1.18612\n",
      "Early stopping, best iteration is:\n",
      "[229]\tvalid_0's rmse: 1.18293\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003363 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7664\n",
      "[LightGBM] [Info] Number of data points in the train set: 6992, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.170624\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 1.179577:  35%|###5      | 7/20 [00:01<00:03,  3.39it/s]\u001b[32m[I 2021-05-07 17:36:36,980]\u001b[0m Trial 49 finished with value: 1.1823484578270893 and parameters: {'lambda_l1': 0.0003760226864690155, 'lambda_l2': 8.159166167312531e-08}. Best is trial 43 with value: 1.1795769222321453.\u001b[0m\n",
      "regularization_factors, val_score: 1.179577:  35%|###5      | 7/20 [00:01<00:03,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalid_0's rmse: 1.18592\n",
      "Early stopping, best iteration is:\n",
      "[255]\tvalid_0's rmse: 1.18235\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003012 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7664\n",
      "[LightGBM] [Info] Number of data points in the train set: 6992, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.170624\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 1.179577:  40%|####      | 8/20 [00:02<00:03,  3.46it/s]\u001b[32m[I 2021-05-07 17:36:37,256]\u001b[0m Trial 50 finished with value: 1.1823485131195317 and parameters: {'lambda_l1': 1.0116919560499535e-05, 'lambda_l2': 0.0002563506241951545}. Best is trial 43 with value: 1.1795769222321453.\u001b[0m\n",
      "regularization_factors, val_score: 1.179577:  40%|####      | 8/20 [00:02<00:03,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalid_0's rmse: 1.18592\n",
      "Early stopping, best iteration is:\n",
      "[255]\tvalid_0's rmse: 1.18235\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002209 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7664\n",
      "[LightGBM] [Info] Number of data points in the train set: 6992, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.170624\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 1.179577:  45%|####5     | 9/20 [00:02<00:03,  3.51it/s]\u001b[32m[I 2021-05-07 17:36:37,532]\u001b[0m Trial 51 finished with value: 1.1823479947101847 and parameters: {'lambda_l1': 0.001657408047871204, 'lambda_l2': 7.940363926220163e-05}. Best is trial 43 with value: 1.1795769222321453.\u001b[0m\n",
      "regularization_factors, val_score: 1.179577:  45%|####5     | 9/20 [00:02<00:03,  3.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalid_0's rmse: 1.18592\n",
      "Early stopping, best iteration is:\n",
      "[255]\tvalid_0's rmse: 1.18235\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002175 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7664\n",
      "[LightGBM] [Info] Number of data points in the train set: 6992, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.170624\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 1.179577:  50%|#####     | 10/20 [00:02<00:02,  3.53it/s]\u001b[32m[I 2021-05-07 17:36:37,811]\u001b[0m Trial 52 finished with value: 1.1829186525888276 and parameters: {'lambda_l1': 2.3553463029919126e-06, 'lambda_l2': 0.03816984200830804}. Best is trial 43 with value: 1.1795769222321453.\u001b[0m\n",
      "regularization_factors, val_score: 1.179577:  50%|#####     | 10/20 [00:02<00:02,  3.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalid_0's rmse: 1.18591\n",
      "Early stopping, best iteration is:\n",
      "[267]\tvalid_0's rmse: 1.18292\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003141 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7664\n",
      "[LightGBM] [Info] Number of data points in the train set: 6992, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.170624\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 1.179577:  55%|#####5    | 11/20 [00:03<00:02,  3.61it/s]\u001b[32m[I 2021-05-07 17:36:38,074]\u001b[0m Trial 53 finished with value: 1.1838911046003096 and parameters: {'lambda_l1': 0.979162984461106, 'lambda_l2': 0.010233769374398816}. Best is trial 43 with value: 1.1795769222321453.\u001b[0m\n",
      "regularization_factors, val_score: 1.179577:  55%|#####5    | 11/20 [00:03<00:02,  3.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalid_0's rmse: 1.18615\n",
      "Early stopping, best iteration is:\n",
      "[216]\tvalid_0's rmse: 1.18389\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002292 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7664\n",
      "[LightGBM] [Info] Number of data points in the train set: 6992, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.170624\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 1.179577:  60%|######    | 12/20 [00:03<00:02,  3.66it/s]\u001b[32m[I 2021-05-07 17:36:38,339]\u001b[0m Trial 54 finished with value: 1.1829254763003878 and parameters: {'lambda_l1': 0.008371186848012323, 'lambda_l2': 0.0014125528815369616}. Best is trial 43 with value: 1.1795769222321453.\u001b[0m\n",
      "regularization_factors, val_score: 1.179577:  60%|######    | 12/20 [00:03<00:02,  3.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalid_0's rmse: 1.18592\n",
      "Early stopping, best iteration is:\n",
      "[267]\tvalid_0's rmse: 1.18293\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002233 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7664\n",
      "[LightGBM] [Info] Number of data points in the train set: 6992, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.170624\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 1.179577:  65%|######5   | 13/20 [00:03<00:01,  3.70it/s]\u001b[32m[I 2021-05-07 17:36:38,602]\u001b[0m Trial 55 finished with value: 1.1823470123706605 and parameters: {'lambda_l1': 0.004570388100220024, 'lambda_l2': 5.639809524412204e-06}. Best is trial 43 with value: 1.1795769222321453.\u001b[0m\n",
      "regularization_factors, val_score: 1.179577:  65%|######5   | 13/20 [00:03<00:01,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalid_0's rmse: 1.18592\n",
      "Early stopping, best iteration is:\n",
      "[255]\tvalid_0's rmse: 1.18235\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003140 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7664\n",
      "[LightGBM] [Info] Number of data points in the train set: 6992, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.170624\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 1.179577:  70%|#######   | 14/20 [00:03<00:01,  3.64it/s]\u001b[32m[I 2021-05-07 17:36:38,888]\u001b[0m Trial 56 finished with value: 1.1829206752088806 and parameters: {'lambda_l1': 0.023556817507148404, 'lambda_l2': 1.6542971717440978e-08}. Best is trial 43 with value: 1.1795769222321453.\u001b[0m\n",
      "regularization_factors, val_score: 1.179577:  70%|#######   | 14/20 [00:03<00:01,  3.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalid_0's rmse: 1.18592\n",
      "Early stopping, best iteration is:\n",
      "[267]\tvalid_0's rmse: 1.18292\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002172 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7664\n",
      "[LightGBM] [Info] Number of data points in the train set: 6992, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.170624\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 1.179577:  75%|#######5  | 15/20 [00:04<00:01,  3.58it/s]\u001b[32m[I 2021-05-07 17:36:39,176]\u001b[0m Trial 57 finished with value: 1.1829161798805976 and parameters: {'lambda_l1': 0.03676803888808421, 'lambda_l2': 5.32789519547495e-07}. Best is trial 43 with value: 1.1795769222321453.\u001b[0m\n",
      "regularization_factors, val_score: 1.179577:  75%|#######5  | 15/20 [00:04<00:01,  3.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalid_0's rmse: 1.18591\n",
      "Early stopping, best iteration is:\n",
      "[267]\tvalid_0's rmse: 1.18292\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002856 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7664\n",
      "[LightGBM] [Info] Number of data points in the train set: 6992, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.170624\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 1.179577:  80%|########  | 16/20 [00:04<00:01,  3.60it/s]\u001b[32m[I 2021-05-07 17:36:39,451]\u001b[0m Trial 58 finished with value: 1.1861762623051297 and parameters: {'lambda_l1': 5.21083301589759, 'lambda_l2': 6.283589745019629e-06}. Best is trial 43 with value: 1.1795769222321453.\u001b[0m\n",
      "regularization_factors, val_score: 1.179577:  80%|########  | 16/20 [00:04<00:01,  3.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalid_0's rmse: 1.18971\n",
      "Early stopping, best iteration is:\n",
      "[231]\tvalid_0's rmse: 1.18618\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002181 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7664\n",
      "[LightGBM] [Info] Number of data points in the train set: 6992, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.170624\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 1.179577:  85%|########5 | 17/20 [00:04<00:00,  3.58it/s]\u001b[32m[I 2021-05-07 17:36:39,735]\u001b[0m Trial 59 finished with value: 1.1823482477056777 and parameters: {'lambda_l1': 0.0009858947753689138, 'lambda_l2': 3.828094380048916e-07}. Best is trial 43 with value: 1.1795769222321453.\u001b[0m\n",
      "regularization_factors, val_score: 1.179577:  85%|########5 | 17/20 [00:04<00:00,  3.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalid_0's rmse: 1.18592\n",
      "Early stopping, best iteration is:\n",
      "[255]\tvalid_0's rmse: 1.18235\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002191 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7664\n",
      "[LightGBM] [Info] Number of data points in the train set: 6992, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.170624\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 1.178819:  90%|######### | 18/20 [00:05<00:00,  3.54it/s]\u001b[32m[I 2021-05-07 17:36:40,025]\u001b[0m Trial 60 finished with value: 1.1788186459188261 and parameters: {'lambda_l1': 0.3366022576962759, 'lambda_l2': 0.002077215811757353}. Best is trial 60 with value: 1.1788186459188261.\u001b[0m\n",
      "regularization_factors, val_score: 1.178819:  90%|######### | 18/20 [00:05<00:00,  3.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalid_0's rmse: 1.18237\n",
      "Early stopping, best iteration is:\n",
      "[246]\tvalid_0's rmse: 1.17882\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002144 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7664\n",
      "[LightGBM] [Info] Number of data points in the train set: 6992, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.170624\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 1.178819:  95%|#########5| 19/20 [00:05<00:00,  3.58it/s]\u001b[32m[I 2021-05-07 17:36:40,297]\u001b[0m Trial 61 finished with value: 1.1868086355312673 and parameters: {'lambda_l1': 9.42503334526325, 'lambda_l2': 0.09694647697897903}. Best is trial 60 with value: 1.1788186459188261.\u001b[0m\n",
      "regularization_factors, val_score: 1.178819:  95%|#########5| 19/20 [00:05<00:00,  3.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalid_0's rmse: 1.19101\n",
      "Early stopping, best iteration is:\n",
      "[246]\tvalid_0's rmse: 1.18681\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002604 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7664\n",
      "[LightGBM] [Info] Number of data points in the train set: 6992, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.170624\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 1.178328: 100%|##########| 20/20 [00:05<00:00,  3.71it/s]\u001b[32m[I 2021-05-07 17:36:40,543]\u001b[0m Trial 62 finished with value: 1.1783280024699798 and parameters: {'lambda_l1': 0.4287201412385115, 'lambda_l2': 0.0032940034578506517}. Best is trial 62 with value: 1.1783280024699798.\u001b[0m\n",
      "regularization_factors, val_score: 1.178328: 100%|##########| 20/20 [00:05<00:00,  3.61it/s]\n",
      "min_data_in_leaf, val_score: 1.178328:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalid_0's rmse: 1.18067\n",
      "Early stopping, best iteration is:\n",
      "[218]\tvalid_0's rmse: 1.17833\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003175 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7664\n",
      "[LightGBM] [Info] Number of data points in the train set: 6992, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.170624\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 1.178328:  20%|##        | 1/5 [00:00<00:01,  3.54it/s]\u001b[32m[I 2021-05-07 17:36:40,831]\u001b[0m Trial 63 finished with value: 1.1846261729820629 and parameters: {'min_child_samples': 25}. Best is trial 63 with value: 1.1846261729820629.\u001b[0m\n",
      "min_data_in_leaf, val_score: 1.178328:  20%|##        | 1/5 [00:00<00:01,  3.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalid_0's rmse: 1.18925\n",
      "Early stopping, best iteration is:\n",
      "[239]\tvalid_0's rmse: 1.18463\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002343 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7664\n",
      "[LightGBM] [Info] Number of data points in the train set: 6992, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.170624\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 1.178328:  40%|####      | 2/5 [00:00<00:00,  3.56it/s]\u001b[32m[I 2021-05-07 17:36:41,111]\u001b[0m Trial 64 finished with value: 1.185684386605458 and parameters: {'min_child_samples': 100}. Best is trial 63 with value: 1.1846261729820629.\u001b[0m\n",
      "min_data_in_leaf, val_score: 1.178328:  40%|####      | 2/5 [00:00<00:00,  3.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalid_0's rmse: 1.18918\n",
      "Early stopping, best iteration is:\n",
      "[233]\tvalid_0's rmse: 1.18568\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002278 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7664\n",
      "[LightGBM] [Info] Number of data points in the train set: 6992, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.170624\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 1.178328:  60%|######    | 3/5 [00:00<00:00,  3.33it/s]\u001b[32m[I 2021-05-07 17:36:41,434]\u001b[0m Trial 65 finished with value: 1.1824802152897675 and parameters: {'min_child_samples': 5}. Best is trial 65 with value: 1.1824802152897675.\u001b[0m\n",
      "min_data_in_leaf, val_score: 1.178328:  60%|######    | 3/5 [00:00<00:00,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalid_0's rmse: 1.18526\n",
      "[400]\tvalid_0's rmse: 1.18553\n",
      "Early stopping, best iteration is:\n",
      "[308]\tvalid_0's rmse: 1.18248\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002485 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7664\n",
      "[LightGBM] [Info] Number of data points in the train set: 6992, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.170624\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 1.178328:  80%|########  | 4/5 [00:01<00:00,  3.44it/s]\u001b[32m[I 2021-05-07 17:36:41,709]\u001b[0m Trial 66 finished with value: 1.1837288271156363 and parameters: {'min_child_samples': 10}. Best is trial 65 with value: 1.1824802152897675.\u001b[0m\n",
      "min_data_in_leaf, val_score: 1.178328:  80%|########  | 4/5 [00:01<00:00,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalid_0's rmse: 1.18719\n",
      "Early stopping, best iteration is:\n",
      "[232]\tvalid_0's rmse: 1.18373\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003465 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7664\n",
      "[LightGBM] [Info] Number of data points in the train set: 6992, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.170624\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 1.178328: 100%|##########| 5/5 [00:01<00:00,  3.57it/s]\u001b[32m[I 2021-05-07 17:36:41,972]\u001b[0m Trial 67 finished with value: 1.1873739192470518 and parameters: {'min_child_samples': 50}. Best is trial 65 with value: 1.1824802152897675.\u001b[0m\n",
      "min_data_in_leaf, val_score: 1.178328: 100%|##########| 5/5 [00:01<00:00,  3.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalid_0's rmse: 1.19051\n",
      "Early stopping, best iteration is:\n",
      "[215]\tvalid_0's rmse: 1.18737\n",
      "goal_difference  rmse :  1.1245327762759803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesbian-wisdom",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "specified-force",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['年月日', '節', 'H_勝点', 'H_試合', 'H_勝', 'H_分', 'H_敗', 'H_得点', 'H_失点',\n",
       "       'H_得失点差', 'H_rest_days', 'A_勝点', 'A_試合', 'A_勝', 'A_分', 'A_敗', 'A_得点',\n",
       "       'A_失点', 'A_得失点差', 'A_rest_days', 'H_シュート', 'H_枠内シュート', 'H_PKによるシュート',\n",
       "       'H_直接ＦＫ', 'H_間接ＦＫ', 'H_ＣＫ', 'H_クリア', 'H_インターセプト', 'H_オフサイド', 'H_警告',\n",
       "       'H_退場', 'H_３０ｍライン進入', 'H_ペナルティエリア進入', 'H_攻撃回数', 'H_チャンス構築率', 'H_ボール支配率',\n",
       "       'A_シュート', 'A_枠内シュート', 'A_PKによるシュート', 'A_直接ＦＫ', 'A_間接ＦＫ', 'A_ＣＫ',\n",
       "       'A_クリア', 'A_インターセプト', 'A_オフサイド', 'A_警告', 'A_退場', 'A_３０ｍライン進入',\n",
       "       'A_ペナルティエリア進入', 'A_攻撃回数', 'A_チャンス構築率', 'A_ボール支配率', 'goal_difference',\n",
       "       'H_成功したパス', 'H_失敗したパス', 'H_成功したクロス', 'H_失敗したクロス', 'H_成功したスローイン',\n",
       "       'H_失敗したスローイン', 'H_成功したドリブル', 'H_失敗したドリブル', 'H_成功したタックル', 'H_失敗したタックル',\n",
       "       'A_成功したパス', 'A_失敗したパス', 'A_成功したクロス', 'A_失敗したクロス', 'A_成功したスローイン',\n",
       "       'A_失敗したスローイン', 'A_成功したドリブル', 'A_失敗したドリブル', 'A_成功したタックル', 'A_失敗したタックル',\n",
       "       'キックオフ時', 'J1_flg', 'J2_flg', 'J3_flg', 'H_DF', 'H_MF', 'H_FW', 'A_DF',\n",
       "       'A_MF', 'A_FW', 'H_Team', 'A_Team', 'H_監督', 'A_監督'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "female-drawing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outer-smith",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sensitive-mathematics",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "international-citizen",
   "metadata": {},
   "outputs": [],
   "source": [
    "'goal_difference'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
